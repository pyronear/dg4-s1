import numpy as np
import pandas as pd
import open3d as o3d
import laspy
import os
import glob
import urllib.request
import matplotlib.pyplot as plt
import math
from pathlib import Path
import elevation as eio
from osgeo import gdal
from tools import project, signal

def las_to_point(las):
    '''Convert a las object into an array of points x,y,z

    Args:
        las (laspy.LasData): data read from las or laz file

    Returns:
        np.array: reshaped data
    '''
    return np.stack([las.x, las.y, las.z], axis=0).transpose((1, 0))

def downsample(array, by:int): 
    '''Take 1 in "by" elements of array

    Args:
        array (np.array): the data to downsample
        by (int): divide the length of array by this number

    Returns:
        np.array: downsampled data
    '''
    indices = list(range(0,len(array),by))
    downsampled = np.take(array, indices, axis=0)
    return downsampled

def downsample_las(las, by:int): 
    '''Downsample las and then extract las points

    Args:
        las (laspy.LasData): data read from las or laz file
        by (int): divide the length of array by this number

    Returns:
        np.array: reshaped and downsampled data
    '''
    indices = list(range(0,len(las.x),by))
    x = np.take(las.x, indices, axis=0)
    y = np.take(las.y, indices, axis=0)
    z = np.take(las.z, indices, axis=0)
    points = np.stack([x, y, z], axis=0).transpose((1, 0))
    return points

def download_list(datadir, url_file):
    '''Download a list of urls contained in a file

    Args:
        datadir (str): directory where to store data
        url_file (str): filename of the list of urls
    '''
    with open(url_file) as file:
        lines = [line.rstrip() for line in file]
    for link in lines:
        filename = link.split('/')[-1]
        print("Downloading", filename)
        urllib.request.urlretrieve(link, datadir+filename)

def load_las_data(datadir, downsampleby=1000):
    '''Get point cloud from files

    Args:
        datadir (str): directory where to store data
        downsampleby (int, optional): divide the length of array by this number. Defaults to 1000.

    Returns:
        o3d.geometry.PointCloud(): point cloud
    '''
    point_data = np.array([]).reshape(0,3)
    for file in glob.glob(datadir+"*.laz"):
        print("Loading", file)
        las = laspy.read(file)
        new_points = downsample_las(las, downsampleby)
        point_data = np.concatenate((point_data, new_points))
    print("Number of points:", point_data.shape[0])
    # convert to open3d point cloud
    pc = o3d.geometry.PointCloud()
    pc.points = o3d.utility.Vector3dVector(point_data)
    return pc

def download_and_load(datadir, urls_file, downsampleby:int):
    '''One by one: download url, load file, delete file and save extracted pointcloud data for a bunch of 25 files. 
    You can avoid overloading storage space by using download_and_load() instead of download_list() followed by load_las_data().

    Args:
        datadir (str): directory where to store data
        urls_file (str): filename of the list of urls
        downsampleby (int): divide the length of array by this number
    '''
    # read list of urls
    with open(urls_file) as file:
        lines = [line.rstrip() for line in file]
    nb_lines = len(lines)-1
    checkpoint = 25
    nb_check = 1
    point_data = np.array([]).reshape(0,3)
    # process each link
    for i, link in enumerate(lines):
        filename = link.split('/')[-1]
        current_item = f"{i}/{nb_lines} - {filename} - "
        # download the file
        print(current_item+"Downloading", end=' - ')
        try:
            urllib.request.urlretrieve(link, datadir+filename)
        except:
            print("ERROR")
        else:
            # load the laz file
            print("Loading")
            las = laspy.read(datadir+filename)
            # extract needed data 
            new_points = downsample_las(las, downsampleby)
            del las
            point_data = np.concatenate((point_data, new_points))
            del new_points
            # delete file
            os.remove(datadir+filename)
        finally:
            # every 25 files (or last one), save the extracted data points in a pcd file
            if (i%checkpoint==0 and i!=0) or i==nb_lines:
                # convert to open3d point cloud
                pc = o3d.geometry.PointCloud()
                pc.points = o3d.utility.Vector3dVector(point_data)
                # save point cloud
                o3d.io.write_point_cloud(datadir+f"terrain_{nb_check}.pcd", pc)
                print("saved pcd", nb_check)
                nb_check+=1
                # reset point_data
                point_data = np.array([]).reshape(0,3)
                del pc

def load_pcd(datadir, save=""):
    '''Aggregate pcd files generated by download_and_load()

    Args:
        datadir (str): directory where to store data
        save (str, optional): if not empty, save the aggregated data within the requested filename. 
        Files deletion is left to the user. Defaults to "".

    Returns:
        o3d.geometry.PointCloud(): point cloud
    '''
    pc = o3d.geometry.PointCloud()
    for file in glob.glob(datadir+"terrain_*.pcd"):
        pc += o3d.io.read_point_cloud(file)
    if save:
        print("saved")
        o3d.io.write_point_cloud(datadir+save+".pcd", pc)
    return pc

def bounds_from_distance(lat, lon, distance):
    '''Compute bounds around lat lon from given distance

    Args:
        lat (float): latitude
        lon (float): longitude
        distance (float): distance in km

    Returns:
        list : [x1,y1,x2,y2], boundaries around lat lon
    '''
    dlat = (distance/2) / 111.11
    dlon = dlat / math.cos(math.radians(lat))
    return [lon - dlon, lat - dlat, lon + dlon, lat + dlat]

def download_from_eio(datapath, name, lat=0, lon=0, distance=50, bounds=None, epsg='2154'):
    '''Download elevation data and save it as .xyz file
        Filled arguments must be either (lat, lon and distance), or (bounds)
    Args:
        datapath (str): path to the data folder
        name (str): name to identify files
        lat (float, optional): latitude of viewpoint
        lon (float, optional): longitude of viewpoint
        distance (int, optional): distance to load around viewpoint. Defaults to 50.
        bounds (list): [x1, y1, x2, y2], load data within these bounds. 
        epsg (str): projection system id
    '''
    # get bounds
    if not bounds:
        bounds = bounds_from_distance(lat, lon, distance)
    tiff_file = Path.cwd().as_posix()+datapath.replace('.', '')+name+'.tiff'
    # download elevation data
    eio.clip(bounds=bounds, output=tiff_file, product='SRTM3') # take some time proportional to distance
    # open it and translate it to xyz
    xyz_file = datapath+name+'.xyz'
    tiff_data = gdal.Open(tiff_file)
    xyz = gdal.Translate(xyz_file, tiff_data)
    xyz_df = pd.read_csv(xyz_file, sep=' ', names=['x', 'y', 'z'])
    # delete tiff file
    if os.path.exists(tiff_file):
        os.remove(tiff_file)
    # project coordinates to xy
    xyz_df = project.dataframe_to_xy(xyz_df, epsg)
    # save the processed xyz data
    xyz_df.to_csv(xyz_file, sep=' ', header=False, index=False)
    print('File', xyz_file, 'ready.')

def load_skyline(filepath, fov, width, height,  n=5, plot=False):
    '''Load and prepare a skyline as numpy array

    Args:
        filepath (string): path to the .npy file to read
        fov (float): field of view in degrees
        width (int): width of the image from which is extracted the skyline, in pixels
        height (int): height of the image, in pixels
        n (int, optional): smoothing factor, default to 5
        plot (boolean, optional): if true, plot the skyline. Default to False

    Returns:
        np.array (fov,): skyline as a list of size fov
    '''
    # load npy
    image_skyline = np.load(filepath).astype(float)
    # remove useless dimension
    image_skyline = image_skyline[:,0]
    # invert y axis (comes from an image, where 0,0 is on top left corner)
    image_skyline[:,1] = height-image_skyline[:,1]
    # sort
    image_skyline = image_skyline[image_skyline[:, 0].argsort()]
    # get unique x values and indexes
    uniques = np.unique(image_skyline[:, 0], return_index=True)
    x_values = uniques[0].astype(int)
    y_values = []
    # group by x and compute mean of grouped y values
    grouped_by_x = np.split(image_skyline[:,1], uniques[1][1:])
    for ys in grouped_by_x:
        y_values.append(np.mean(ys))
    # interpolate to be sure to have a y value for each x
    full_skyline = np.interp(np.arange(0,width), x_values, y_values)
    # smooth skyline
    smooth_image_skyline = np.convolve(full_skyline, np.ones(n)/n, mode='valid')
    # downsample the image skyline to the fov width
    indices = np.linspace(0, width, num=fov, dtype=int, endpoint=False)
    reduced_image_skyline = np.take(smooth_image_skyline, indices)
    # finally smooth (again) the signal
    reduced_image_skyline = signal.pad_smooth(reduced_image_skyline, n)

    # plot if requested
    if plot:
        plt.xlim(0, width)
        plt.ylim(0, height)
        plt.plot(indices, reduced_image_skyline, linewidth=3, color='blue')
        plt.title('Skyline from image')
        plt.show()

    return reduced_image_skyline